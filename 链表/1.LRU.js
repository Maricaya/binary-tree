/* 如何基于链表实现LRU缓存淘汰算法？
 我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
 1.如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
 2.如果此数据没有在缓存链表中，又可以分为两种情况：
 - 如果此时缓存未满，则将此结点直接插入到链表的头部；
 - 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。
  这样我们就用链表实现了一个LRU缓存，是不是很简单？
  现在我们来看下m缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度 为O(n)。
  实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到O(1)。因为要涉及我们还没有讲
*/
